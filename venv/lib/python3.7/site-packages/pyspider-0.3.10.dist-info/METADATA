Metadata-Version: 2.1
Name: pyspider
Version: 0.3.10
Summary: A Powerful Spider System in Python
Home-page: https://github.com/binux/pyspider
Author: Roy Binux
Author-email: roy@binux.me
License: Apache License, Version 2.0
Keywords: scrapy crawler spider webui
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.6
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Environment :: Web Environment
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Dist: Flask (>=0.10)
Requires-Dist: Jinja2 (>=2.7)
Requires-Dist: chardet (>=2.2)
Requires-Dist: cssselect (>=0.9)
Requires-Dist: lxml
Requires-Dist: pycurl
Requires-Dist: requests (>=2.2)
Requires-Dist: Flask-Login (>=0.2.11)
Requires-Dist: u-msgpack-python (>=1.6)
Requires-Dist: click (>=3.3)
Requires-Dist: six (>=1.5.0)
Requires-Dist: tblib (>=1.3.0)
Requires-Dist: wsgidav (>=2.0.0)
Requires-Dist: tornado (<=4.5.3,>=3.2)
Requires-Dist: pyquery
Provides-Extra: all
Requires-Dist: mysql-connector-python (>=1.2.2) ; extra == 'all'
Requires-Dist: pymongo (>=2.7.2) ; extra == 'all'
Requires-Dist: redis ; extra == 'all'
Requires-Dist: redis-py-cluster ; extra == 'all'
Requires-Dist: psycopg2 ; extra == 'all'
Requires-Dist: elasticsearch (<2.4.0,>=2.0.0) ; extra == 'all'
Requires-Dist: kombu ; extra == 'all'
Requires-Dist: amqp (>=2.1.1) ; extra == 'all'
Requires-Dist: SQLAlchemy (>=0.9.7) ; extra == 'all'
Provides-Extra: test
Requires-Dist: unittest2 (>=0.5.1) ; extra == 'test'
Requires-Dist: coverage ; extra == 'test'
Requires-Dist: httpbin (<=0.5.0) ; extra == 'test'
Requires-Dist: pyproxy (>=0.1.6) ; extra == 'test'
Requires-Dist: easywebdav ; extra == 'test'

pyspider [![Build Status]][Travis CI] [![Coverage Status]][Coverage] [![Try]][Demo]
========

A Powerful Spider(Web Crawler) System in Python. **[TRY IT NOW!][Demo]**

- Write script in Python
- Powerful WebUI with script editor, task monitor, project manager and result viewer
- [MySQL](https://www.mysql.com/), [MongoDB](https://www.mongodb.org/), [Redis](http://redis.io/), [SQLite](https://www.sqlite.org/), [Elasticsearch](https://www.elastic.co/products/elasticsearch); [PostgreSQL](http://www.postgresql.org/) with [SQLAlchemy](http://www.sqlalchemy.org/) as database backend
- [RabbitMQ](http://www.rabbitmq.com/), [Beanstalk](http://kr.github.com/beanstalkd/), [Redis](http://redis.io/) and [Kombu](http://kombu.readthedocs.org/) as message queue
- Task priority, retry, periodical, recrawl by age, etc...
- Distributed architecture, Crawl Javascript pages, Python 2.{6,7}, 3.{3,4,5,6} support, etc...

Tutorial: [http://docs.pyspider.org/en/latest/tutorial/](http://docs.pyspider.org/en/latest/tutorial/)  
Documentation: [http://docs.pyspider.org/](http://docs.pyspider.org/)  
Release notes: [https://github.com/binux/pyspider/releases](https://github.com/binux/pyspider/releases)  

Sample Code 
-----------

```python
from pyspider.libs.base_handler import *


class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        self.crawl('http://scrapy.org/', callback=self.index_page)

    @config(age=10 * 24 * 60 * 60)
    def index_page(self, response):
        for each in response.doc('a[href^="http"]').items():
            self.crawl(each.attr.href, callback=self.detail_page)

    def detail_page(self, response):
        return {
            "url": response.url,
            "title": response.doc('title').text(),
        }
```

[![Demo][Demo Img]][Demo]


Installation
------------

* `pip install pyspider`
* run command `pyspider`, visit [http://localhost:5000/](http://localhost:5000/)

**WARNING:** WebUI is open to the public by default, it can be used to execute any command which may harm your system. Please use it in an internal network or [enable `need-auth` for webui](http://docs.pyspider.org/en/latest/Command-Line/#-config).

Quickstart: [http://docs.pyspider.org/en/latest/Quickstart/](http://docs.pyspider.org/en/latest/Quickstart/)

Contribute
----------

* Use It
* Open [Issue], send PR
* [User Group]
* [中文问答](http://segmentfault.com/t/pyspider)


TODO
----

### v0.4.0

- [ ] a visual scraping interface like [portia](https://github.com/scrapinghub/portia)


License
-------
Licensed under the Apache License, Version 2.0


[Build Status]:         https://img.shields.io/travis/binux/pyspider/master.svg?style=flat
[Travis CI]:            https://travis-ci.org/binux/pyspider
[Coverage Status]:      https://img.shields.io/coveralls/binux/pyspider.svg?branch=master&style=flat
[Coverage]:             https://coveralls.io/r/binux/pyspider
[Try]:                  https://img.shields.io/badge/try-pyspider-blue.svg?style=flat
[Demo]:                 http://demo.pyspider.org/
[Demo Img]:             https://github.com/binux/pyspider/blob/master/docs/imgs/demo.png
[Issue]:                https://github.com/binux/pyspider/issues
[User Group]:           https://groups.google.com/group/pyspider-users


